{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import notears.utils\n",
    "from bnlearn import bnlearn\n",
    "from notears.linear import notears_linear\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from dagsim.baseDS import Graph, Generic\n",
    "from notears import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bnlearn as bn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "LR = LogisticRegression(random_state=0)\n",
    "\n",
    "# Ground truth definition using a logit (sigmoid) function\n",
    "def log_transformation(params0, params1, params2, params3):\n",
    "    sum = params0 * 2 + params1 - params2 + params3 + random.randint(0,1)\n",
    "    y = 1 / (1 + np.exp(-sum))\n",
    "    y = 1 if y > 0.5 else 0\n",
    "    return y\n",
    "\n",
    "# DAG setup - no interaction\n",
    "def setup_dag():\n",
    "    Prior1 = Generic(name=\"A\", function=np.random.binomial, arguments={\"n\":1, \"p\":0.5})\n",
    "    Prior2 = Generic(name=\"B\", function=np.random.binomial, arguments={\"n\":1, \"p\":0.5})\n",
    "    Prior3 = Generic(name=\"C\", function=np.random.binomial, arguments={\"n\":1, \"p\":0.5})\n",
    "    Prior4 = Generic(name=\"D\", function=np.random.binomial, arguments={\"n\":1, \"p\":0.5})\n",
    "    Node1 = Generic(name=\"E\", function=log_transformation, arguments={\"params0\": Prior1, \"params1\": Prior2, \"params2\": Prior3, \"params3\": Prior4})\n",
    "\n",
    "    listNodes = [Prior1, Prior2, Prior3, Prior4, Node1]\n",
    "    my_graph = Graph(\"Logistic Regression - Real-world\", listNodes)\n",
    "\n",
    "    # simulate data for training and testing, with study-specific sample sizes\n",
    "    train = my_graph.simulate(num_samples=10000, csv_name=\"train\")\n",
    "    test = my_graph.simulate(num_samples=5000, csv_name=\"test\")\n",
    "\n",
    "setup_dag()\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# import the saved training data\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "train_data_numpy = train_data.to_numpy()\n",
    "x_train = train_data.iloc[:, 0:4].to_numpy().reshape([-1, 4]) # num predictors\n",
    "print(\"x_train\", x_train.shape)\n",
    "y_train = train_data.iloc[:, 4].to_numpy().reshape([-1]).ravel() # outcome\n",
    "print(\"y_train\", y_train.shape)\n",
    "\n",
    "# Sklearn - Construct logistic regression model and fit using simulated training data\n",
    "def model_training(x_train, y_train):\n",
    "    LR.fit(x_train, y_train)\n",
    "    print(\"Coefficient: \", LR.coef_)\n",
    "    print(\"Intercept: \", LR.intercept_)\n",
    "\n",
    "model_training(x_train, y_train)\n",
    "\n",
    "# import the saved testing data\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "x_test = test_data.iloc[:, 0:4].to_numpy().reshape([-1, 4])\n",
    "#print(\"x_test\", x_test.shape)\n",
    "y_test = test_data.iloc[:, 4].to_numpy().reshape([-1])\n",
    "#print(\"y_test\", y_test.shape)\n",
    "\n",
    "def model_evaluate(LR):\n",
    "    y_pred = LR.predict(x_test)\n",
    "    y_pred_proba = LR.predict_proba(x_test)[:,1]\n",
    "    LR.score(x_test, y_pred)\n",
    "    print(\"Report: Output evaluation measures\")\n",
    "    # Return the evaluation score (R^2) of the model on the testing data\n",
    "    print(\"Accuracy of 100: \", accuracy_score(y_test, y_pred)*100)\n",
    "    score = LR.score(x_test, y_pred)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)*100\n",
    "    print(\"AUC ROC curve: \", auc_roc)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(\"Mean Absolute Error: \", mae)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Mean Squared Error: \", mse)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square=True, cmap='Greens_r');\n",
    "    plt.ylabel('Actual label');\n",
    "    plt.xlabel('Predicted label');\n",
    "    all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "    plt.title(all_sample_title, size=15);\n",
    "    plt.show()\n",
    "\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    clf = clf.fit(x_train[:, 0:4], y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"(Single-Simulated) Accuracy on Test set (DecisionTree)\", metrics.accuracy_score(y_test, y_pred))\n",
    "    rf = RandomForestClassifier(random_state=0)\n",
    "    rf = rf.fit(x_train, y_train)\n",
    "    n_scores = cross_val_score(rf, x_train, y_train,\n",
    "                               scoring='accuracy')\n",
    "    print('(Single-Simulated) Accuracy on Test set (RandomForestClassifier):', np.average(n_scores),\n",
    "          '%.')\n",
    "\n",
    "\n",
    "model_evaluate(LR)\n",
    "\n",
    "def bnlearn_sampling():\n",
    "    DAG = bn.structure_learning.fit(train_data[0:100])#, methodtype='hc', scoretype='bic')\n",
    "    DAG = bn.parameter_learning.fit(DAG, train_data[0:100], methodtype='maximumlikelihood', verbose=0)\n",
    "    bn_train_output = bn.sampling(DAG, n=10000)\n",
    "    bn_test_output = bn.sampling(DAG, n=5000)\n",
    "    np.savetxt('Z_est_train.csv', bn_train_output, delimiter=',')\n",
    "    np.savetxt('Z_est_test.csv', bn_test_output, delimiter=',')\n",
    "\n",
    "bnlearn_sampling()\n",
    "\n",
    "def notears_sampling():\n",
    "    nt_sampling = notears_linear(train_data_numpy[0:100], lambda1=0.01, loss_type='l2')\n",
    "    nt_sampling_train = utils.simulate_linear_sem(nt_sampling, 10000, 'logistic')\n",
    "    nt_sampling_test = utils.simulate_linear_sem(nt_sampling, 5000, 'logistic')\n",
    "    np.savetxt('W_est_train.csv', nt_sampling_train, delimiter=',')\n",
    "    np.savetxt('W_est_test.csv', nt_sampling_test, delimiter=',')\n",
    "\n",
    "notears_sampling()\n",
    "\n",
    "no_tears_sample_train = pd.read_csv('W_est_train.csv')\n",
    "#print(\"no tears samples - Training set\")\n",
    "#print(no_tears_sample_train)\n",
    "no_tears_sample_test = pd.read_csv('W_est_test.csv')\n",
    "#print(\"no tears samples - Test set\")\n",
    "#print(no_tears_sample_test)\n",
    "bn_learn_sample_train = pd.read_csv('Z_est_train.csv')\n",
    "#print(\"bn learn samples - Training set\")\n",
    "#print(bn_learn_sample_train)\n",
    "bn_learn_sample_test = pd.read_csv('Z_est_test.csv')\n",
    "#print(\"bn learn samples - Test set\")\n",
    "#print(bn_learn_sample_test)\n",
    "\n",
    "\n",
    "def decision_tree():\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    clf = clf.fit(bn_learn_sample_train.iloc[:,0:4], bn_learn_sample_train.iloc[:,4])\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"(Double-Simulated) Accuracy of bnlearn on Test set (DecisionTree)\", metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "    clf = clf.fit(no_tears_sample_train.iloc[:,0:4], no_tears_sample_train.iloc[:,4])\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"(Double-Simulated) Accuracy of no_tears on Test set (DecisionTree)\", metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "decision_tree()\n",
    "\n",
    "def random_forest():\n",
    "    rf = RandomForestClassifier(random_state=0)\n",
    "    rf = rf.fit(bn_learn_sample_train.iloc[:,0:4], bn_learn_sample_train.iloc[:,4])\n",
    "    n_scores = cross_val_score(rf, bn_learn_sample_train.iloc[:,0:4], bn_learn_sample_train.iloc[:,4], scoring='accuracy')\n",
    "    print('(Double-Simulated) Accuracy of bn_learn on Test set (RandomForestClassifier):', np.average(n_scores), '%.')\n",
    "\n",
    "    rf = rf.fit(no_tears_sample_train.iloc[:, 0:4], no_tears_sample_train.iloc[:, 4])\n",
    "    n_scores = cross_val_score(rf, no_tears_sample_train.iloc[:,0:4], no_tears_sample_train.iloc[:,4], scoring='accuracy')\n",
    "    print('(Double-Simulated) Accuracy of no_tears on Test set (RandomForestClassifier):', np.average(n_scores), '%.')\n",
    "\n",
    "random_forest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
