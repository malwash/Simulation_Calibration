{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import notears.utils\n",
    "from bnlearn import bnlearn\n",
    "from notears.linear import notears_linear\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from baseDS import Graph, Generic\n",
    "from notears import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bnlearn as bn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "LR = LogisticRegression(random_state=0)\n",
    "\n",
    "# Ground truth definition using a logit (sigmoid) function\n",
    "def log_transformation(params0, params1, params2, params3):\n",
    "    sum = params0 * 2 + params1 - params2 + params3 + random.randint(0,1)\n",
    "    y = 1 / (1 + np.exp(-sum))\n",
    "    #1 model with 4 x binary, with binary y with logistic regression\n",
    "    #rank random forest, linear regression\n",
    "    #Hot code categorical examples\n",
    "    #1 - 0-10\n",
    "    #2 - 10-25\n",
    "    #instead of bionomal arugment would need categorical argument returning one of either of the values\n",
    "    y = 1 if y > 0.5 else 0\n",
    "    return y\n",
    "\n",
    "# DAG setup - no interaction\n",
    "def setup_dag():\n",
    "    Prior1 = Generic(name=\"A\", function=np.random.binomial, arguments={\"n\":1, \"p\":0.5})\n",
    "    Prior2 = Generic(name=\"B\", function=np.random.binomial, arguments={\"n\":1, \"p\":0.5})\n",
    "    Prior3 = Generic(name=\"C\", function=np.random.binomial, arguments={\"n\":1, \"p\":0.5})\n",
    "    Prior4 = Generic(name=\"D\", function=np.random.binomial, arguments={\"n\":1, \"p\":0.5})\n",
    "    Node1 = Generic(name=\"E\", function=log_transformation, arguments={\"params0\": Prior1, \"params1\": Prior2, \"params2\": Prior3, \"params3\": Prior4})\n",
    "\n",
    "    listNodes = [Prior1, Prior2, Prior3, Prior4, Node1]\n",
    "    my_graph = Graph(\"Logistic Regression - Real-world\", listNodes)\n",
    "\n",
    "    # simulate data for training and testing, with study-specific sample sizes\n",
    "    train = my_graph.simulate(num_samples=10000, csv_name=\"train\")\n",
    "    test = my_graph.simulate(num_samples=5000, csv_name=\"test\")\n",
    "\n",
    "setup_dag()\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# import the saved training data\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "train_data_numpy = train_data.to_numpy()\n",
    "x_train = train_data.iloc[:, 0:4].to_numpy().reshape([-1, 4]) # num predictors\n",
    "print(\"x_train\", x_train.shape)\n",
    "y_train = train_data.iloc[:, 4].to_numpy().reshape([-1]).ravel() # outcome\n",
    "print(\"y_train\", y_train.shape)\n",
    "\n",
    "# Sklearn - Construct logistic regression model and fit using simulated training data\n",
    "def model_training(x_train, y_train):\n",
    "    LR.fit(x_train, y_train)\n",
    "    print(\"Coefficient: \", LR.coef_)\n",
    "    print(\"Intercept: \", LR.intercept_)\n",
    "\n",
    "model_training(x_train, y_train)\n",
    "\n",
    "# import the saved testing data\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "x_test = test_data.iloc[:, 0:4].to_numpy().reshape([-1, 4])\n",
    "print(\"x_test\", x_test.shape)\n",
    "y_test = test_data.iloc[:, 4].to_numpy().reshape([-1])\n",
    "print(\"y_test\", y_test.shape)\n",
    "\n",
    "def model_evaluate(LR):\n",
    "    y_pred = LR.predict(x_test)\n",
    "    y_pred_proba = LR.predict_proba(x_test)[:,1]\n",
    "    LR.score(x_test, y_pred)\n",
    "    print(\"Report: Output evaluation measures\")\n",
    "\n",
    "    # Return the evaluation score (R^2) of the model on the testing data\n",
    "    print(\"Accuracy of 100: \", accuracy_score(y_test, y_pred)*100)\n",
    "    score = LR.score(x_test, y_pred)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)*100\n",
    "    print(\"AUC ROC curve: \", auc_roc)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(\"Mean Absolute Error: \", mae)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Mean Squared Error: \", mse)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square=True, cmap='Greens_r');\n",
    "    plt.ylabel('Actual label');\n",
    "    plt.xlabel('Predicted label');\n",
    "    all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "    plt.title(all_sample_title, size=15);\n",
    "    plt.show()\n",
    "\n",
    "model_evaluate(LR)\n",
    "\n",
    "def bnlearn_sampling():\n",
    "    edges = [('A', 'E'),\n",
    "             ('B', 'E'),\n",
    "             ('C', 'E'),\n",
    "             ('D', 'E')]\n",
    "    DAG = bnlearn.make_DAG(edges)\n",
    "    bn.plot(DAG)\n",
    "    print(DAG['adjmat'])\n",
    "    print(type(train_data))\n",
    "    DAG = bn.parameter_learning.fit(DAG, train_data, methodtype='maximumlikelihood')\n",
    "    bn_sample = bn.sampling(DAG, n=100)\n",
    "    np.savetxt('Z_est.csv', bn_sample, delimiter=',')\n",
    "\n",
    "bnlearn_sampling()\n",
    "\n",
    "def notears_sampling():\n",
    "    nt_sampling = notears_linear(train_data_numpy[0:100], lambda1=0.01, loss_type='l2')\n",
    "    assert utils.is_dag(nt_sampling)\n",
    "    np.savetxt('W_est.csv', nt_sampling, delimiter=',')\n",
    "\n",
    "notears_sampling()\n",
    "\n",
    "no_tears_sample = pd.read_csv('W_est.csv')\n",
    "print(\"no tears samples\")\n",
    "print(no_tears_sample)\n",
    "bn_learn_sample = pd.read_csv('Z_est.csv')\n",
    "print(\"bn learn samples\")\n",
    "print(bn_learn_sample)\n",
    "\n",
    "\n",
    "def decision_tree():\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    clf = clf.fit(bn_learn_sample.iloc[:,0:4], bn_learn_sample.iloc[:,4])\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    print(\"Accuracy of bn_learn (DecisionTree)\", metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "    clf = clf.fit(no_tears_sample.iloc[:,0:4], no_tears_sample.iloc[:,4])\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    print(\"Accuracy of no_tears (DecisionTree)\", metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "decision_tree()\n",
    "\n",
    "def random_forest():\n",
    "    rf = RandomForestClassifier(random_state=0)\n",
    "    rf = rf.fit(bn_learn_sample.iloc[:,0:4], bn_learn_sample.iloc[:,4])\n",
    "    n_scores = cross_val_score(rf, bn_learn_sample.iloc[:,0:4], bn_learn_sample.iloc[:,4], scoring='accuracy')\n",
    "    print('Accuracy of bn_learn (RandomForestClassifier):', np.average(n_scores), '%.')\n",
    "\n",
    "    rf = rf.fit(no_tears_sample.iloc[:, 0:4], no_tears_sample.iloc[:, 4])\n",
    "    n_scores = cross_val_score(rf, x_test, y_test, scoring='accuracy')\n",
    "    print('Accuracy of no_tears (RandomForestClassifier):', np.average(n_scores), '%.')\n",
    "\n",
    "random_forest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
